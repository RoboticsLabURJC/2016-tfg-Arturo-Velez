\hspace{1 cm} La visión artificial está ganando muchos adeptos en los últimos años debido al gran potencial que tiene. Lo interesante de esta tecnología es que algo tan normal para los humanos como es ver y procesar la información recibida por nuestros ojos, para las máquinas supone un reto. Gracias al desarrollo de este trabajo de fin de grado, se ha aprendido paso a paso cómo las máquinas son capaces mediante algoritmos de procesar una información recibida por una cámara y realizar una acción, así como la capacidad de tomar decisiones de manera autónoma.\\

\section{Conclusiones}
Los objetivos planteados en el capítulo 2 se han desarrollado tal y como se ha explicado en el capítulo 4. Estos algoritmos desarrollados son capaces de realizar una percepción visual aplicando desde filtros de color al seguimiento de puntos de interés en objetos con textura. Además, se han desarrollado también unos algoritmos capaces de realizar una búsqueda y un seguimiento de un objeto. Como se explica en el capítulo 5, los experimentos que se han hecho con el componente validan su funcionamiento, ya que cumple con los objetivos planteados.\\

Ha sido necesario aprender como ven las máquinas y que son capaces de hacer con esa información. De ahí que las primeras pruebas que se hicieran fuesen con objetos simples, formas y colores sencillos en lugar de objetos más complejos. Una de las partes más importantes del presente trabajo de fin de grado fue el aprendizaje del procesamiento básico de imágenes utilizando la biblioteca OpenCV y aplicar los datos del mismo a unos mecanismos de control.\\

Después de ese aprendizaje básico, las formas básicas de los objetos pasan a ser puntos en una imagen real gracias a las características que tienen las texturas. Aquí es donde este trabajo de fin de grado tiene su aportación a este campo. Aplicando las funciones de OpenCV, \texttt{cv2.goodFeaturesToTrack()} y  \texttt{cv2.calcOpticalFlowPyrLK()} (véase la sección 4.2), se ha podido hacer un seguimiento visual de estos puntos que definen unas características, las cuales a su vez describen el objeto, por lo tanto, se hace un seguimiento visual del objeto.\\

Se han tratado los datos que las funciones de percepción visual ofrecían, y se han desarrollado algoritmos acordes al objetivo sobre el que se centraba el tema del trabajo, generando una salida a unos datos de entrada. El desarrollo de algoritmos para realizar la búsqueda, donde el drone se desplaza por el escenario siguiendo un patrón, y seguimiento del objeto dentro del escenario de Gazebo, gracias a los datos extraídos de la imagen (véase la sección 4.3) y haciendo uso de la función de control \texttt{cmdVel.sendCMDvel} como director de vuelo del drone, hace que se completen los objetivos marcados inicialmente.\\

En la parte experimental se valida que ahora el componente es capaz de seguir un objeto más complejo frente a los antecedentes que existían previos a este desarrollo, ya que ahora es capaz de seguir objetos con una textura frente a un objetos con un color llamativo. Esto hace que funcione con una mayor variedad de objetos, acercando el comportamiento a objetos más realistas. En esta fase se hicieron una gran cantidad de pruebas una por una de las partes que componen el componente en su versión final (véase el capítulo 5).\\

Además de que el desarrollo cumple con los objetivos inicialmente marcados, cumple también con los requisitos que se definieron. El componente funciona con la versión 5.5 de JdeRobot junto con la versión 7.4 de Gazebo. El procesamiento de las imágenes es rápido y permite al drone realizar correctamente el seguimiento (véase la sección 5.1). En ocasiones la velocidad de procesamiento es más lenta, depende de la capacidad que tenga la máquina sobre la que se esta simulando y ejecutando el componente. Pese a que hay errores en el cálculo de los puntos (véase la sección 5.2), son mínimos, por lo que el componente es robusto y minimiza los errores ejecutándose de una manera correcta. Y por último, cumple con el requisito de ser capaz de seguir diferentes objetos (sección 5.1, figuras 5.8 y 5.9).\\
 
Durante el desarrollo del trabajo se han podido emplear diferentes bibliotecas funcionando con el lenguaje de programación Python, el cual se ha aprendido y se ha adquirido un buen nivel, pudiendo llevar a la práctica conceptos que previamente eran solo teóricos, lo que ha permitido ampliar el conocimiento sobre visión artificial y el poder conocer más en profundidad los algoritmos empleados, logrando así desarrollar algoritmos de percepción para objetos complejos. Ademas, ha habido un aprendizaje de la plataforma JdeRobot, la cual ha permitido una ampliación importante del conocimiento sobre el mundo de la robótica y el control de robots y drones, y como estos se relacionan con el entorno.\\

En mi opinión, este aprendizaje ha sido muy útil y muy interesante para el desarrollo de nuevas tecnologías de visión artificial, ya no solo centradas en drones, si no en cualquier aspecto de la robótica que disponga de una cámara y una capacidad de proceso que permita ejecutar este tipo de algoritmos.\\

\section{Trabajos futuros}
\hspace{1 cm} Sin salirse de la temática de un drone persiguiendo a un objeto con textura, podemos desarrollar aún más este trabajo añadiendo una clasificación de características, es decir, haciendo que después de que este obtenga las características, clasifique los objetos en función de los datos que haya obtenido, para de este modo crear una base de datos con objetos predefinidos. Con esto se pueden desarrollar algoritmos de reconocimiento de objetos por patrones o tipos de objetos.\\ 

También cabe la posibilidad de desarrollar redes neuronales o con técnicas de SVM para que haya un aprendizaje más profundo para detección y clasificación de objetos, pudiendo dotar al drone de una capacidad para tomar decisiones más complejas.\\

En la parte del simulador Gazebo, se pueden desarrollar y se están desarrollando escenario más realistas, y empleando texturas dará una sensación de que esas pruebas están realizadas de la manera más próxima a la realidad y así poder hacer el seguimiento de personas y vehículos.\\

Respecto a los drones, la primera línea futura a seguir es llevar el desarrollo hecho en el simulador al mundo real y probarlo con el drone real ArDrone2 de Parrot. También se pueden desarrollar soporte para más modelos en el mercado, consiguiendo que haya más variedad de drones disponibles para ejecutar el componente. Actualmente, con JdeRobot, cabe destacar el trabajo de Diego Jiménez Bravo\footnote{jderobot.org/Jimenez-tfg}, que está desarrollando soporte para el modelo 3DR Solo Drone y el trabajo de Jose Antonio Fernández\footnote{jderobot.org/Jafernandez}, cuyo tema se centra en desarrollar soporte en un avión.\\

Dejando de lado un poco el tema sobre el que se ha fundamentado el trabajo, y teniendo en cuenta que el tema de la infraestructura ha sido explicado aquí, un trabajo futuro es desarrollar imágenes de los componentes para que puedan ser plug and play, es decir, que tenga todo lo necesario para que el usuario pueda ejecutar los algoritmos sin que nada más sea necesario previamente, por ejemplo, poniendo esas imágenes en servicios cloud o haciendo despliegues mediante contenedores.\\

Por último, el que más abanico de posibilidades da para desarrollo al ser más general, es la visión artificial, en la cual se pueden desarrollar, por ejemplo, un reconocimiento facial y de gestos, y aplicar esta tecnología no solo a drones sino también a sistemas de seguridad y control de maquinaria mediante la cual un coche podría ser conducido solamente con la mirada, apuntando con los ojos allá donde el conductor desea ir. También se puede desarrollar un sistema de detección de enfermedades en la piel mediante un reconocimiento de la textura que estas presenten, otorgando a los pacientes un método de diagnóstico sin ni siquiera tener que asistir al médico. Podemos aplicar también el análisis de texturas en el mundo de las infraestructuras, por ejemplo, detectando en una pared si los ladrillos han sido correctamente colocados y si se encuentran en buen estado.\\

Esto son solo un ejemplo de las posibilidades de desarrollo que existen en el mundo de la visión artificial, de los drones y de los simuladores de entornos virtuales, pero las posibilidades de desarrollo de diferentes aplicaciones son casi infinitas.\\